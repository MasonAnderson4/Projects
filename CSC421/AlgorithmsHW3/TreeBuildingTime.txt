Part 1

TreeSet + Random
Enter the initial tree size: 100
Double until this size: 1000000
(T)reeSet or (B)inarySearchTree? T
(R)andom or (S)orted data? R
100 1
200 0
400 1
800 1
1600 1
3200 2
6400 3
12800 7
25600 15
51200 34
102400 51
204800 94
409600 255
819200 646
This data follows the expected time efficiency of O(N log N) for a random TreeSet.

TreeSet + Sorted
Enter the initial tree size: 100
Double until this size: 1000000
(T)reeSet or (B)inarySearchTree? T
(R)andom or (S)orted data? S
100 1
200 1
400 1
800 1
1600 1
3200 1
6400 4
12800 8
25600 6
51200 10
102400 23
204800 52
409600 106
819200 232
This data also follows the expected time efficiency of O(N log N) for a sorted TreeSet as described in the assignment.

BST + Random
Enter the initial tree size: 100
Double until this size: 1000000
(T)reeSet or (B)inarySearchTree? B
(R)andom or (S)orted data? R
100 1
200 0
400 0
800 0
1600 1
3200 1
6400 3
12800 3
25600 8
51200 19
102400 45
204800 106
409600 272
819200 626
This data follows the expected time efficiency of O(N log N) and stays relatively balanced as expected.

BST + Sorted
Enter the initial tree size: 100
Double until this size: 1000000
(T)reeSet or (B)inarySearchTree? B
(R)andom or (S)orted data? S
100 1
200 1
400 3
800 4
1600 11
3200 49
6400 214
12800 840
Exception in thread "main" java.lang.StackOverflowError
	at AlgorithmsHW3/HW3.BinarySearchTree.add(BinarySearchTree.java:27)
	at AlgorithmsHW3/HW3.BinarySearchTree.add(BinarySearchTree.java:27)
	at AlgorithmsHW3/HW3.BinarySearchTree.add(BinarySearchTree.java:27)
	at AlgorithmsHW3/HW3.BinarySearchTree.add(BinarySearchTree.java:27)
This data initially follows the expected time efficiency of O(N^2) for a sorted BinarySearchTree before crashing. 
It crashed due to a stack overflow error because the recursive depth of the add method becoming too large as the data 
is a linear chain.


Part 5.

BST + Random
Enter the initial tree size: 100
Double until this size: 1000000
(T)reeSet or (B)inarySearchTree? B
(R)andom or (S)orted data? R
100 1
200 1
400 1
800 1
1600 1
3200 2
6400 4
12800 7
25600 12
51200 26
102400 53
204800 130
409600 279
819200 707
This data is very similar to the original data from part 1. It still operates in O(N log N), it just takes slightly longer 
due to the rebalancing overhead of the tree.

Enter the initial tree size: 100
Double until this size: 1000000
(T)reeSet or (B)inarySearchTree? B
(R)andom or (S)orted data? S
100 2
200 1
400 2
800 5
1600 13
3200 26
6400 53
12800 289
25600 564
51200 2138
102400 7972
204800 30036
409600 131118
819200 1285293

This time it actually worked and displays O(N^2/log N), which is better than O(N^2) that was expected in part 1. 
That is because of balancing, but the timings are also a little longer the higher up they get due to the overhead 
time of the rebalancing.
